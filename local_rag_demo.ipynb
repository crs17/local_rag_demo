{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5c1de6ad",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Private AI Chat for Internal Knowledge\"\n",
    "author: \"Chresten R. Søndergaard\"\n",
    "title-block-banner: true\n",
    "title-block-style: default\n",
    "date: \"2026-02-05\"\n",
    "abstract: >\n",
    "    Here we will demonstrate how to run a local *Retrieval Augmented Generation* (RAG) \n",
    "    agent where everything is local including the vector store and the language models (embedding and LLM). \n",
    "    This can be desirable if you want to make internal documents *chattable* but do not \n",
    "    wish to send them across the Internet for processing in the cloud.\n",
    "    This page is part of the [local_rag_demo](https://github.com/crs17/local_rag_demo) repository \n",
    "    which contains all the code for the demo.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd75149",
   "metadata": {},
   "source": [
    "## Why this matters for your business\n",
    "- The local set up allows for data privacy (no cloud)\n",
    "- No accumulating token costs\n",
    "- Works with internal documents e.g. PDFs\n",
    "- Audible answers: the exact text chunk used to generate the answer can be identified\n",
    "- Offline / air-gapped mode is possible "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671405a2",
   "metadata": {},
   "source": [
    "## Brief tech stack overview\n",
    "- The [Ollama](https://ollama.com) official docker image is used managing and running the language models.\n",
    "- We deploy Meta's [Llama3.2](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/) large language model and Nomic's [nomic-embed-text](https://www.nomic.ai/news/nomic-embed-text-v1) embedding model.\n",
    "- [Weaviate](https://weaviate.io) is used as vector store.\n",
    "- [LangChain](https://www.langchain.com) is used for orchestration of the RAG agent.\n",
    "- The agent is deployed locally with the [LangGraph](https://www.langchain.com/langgraph) server.\n",
    "- Finally, the [Agent Chat UI](https://docs.langchain.com/oss/python/langchain/ui) app is chosen as web UI.\n",
    "\n",
    "The flow of information is shown below. The user inputs a query into the UI which passes the query to the agent. The agent can use the vector store to retrieve relevant information and use the LLM to generate the answer.\n",
    "\n",
    "![Architecture overview](static/architecture.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8beffb9",
   "metadata": {},
   "source": [
    "## Deployment of models\n",
    "Firstly, we build and run the Ollama and Weaviate docker images and supsequently, we can fetch the Ollama and Nomic models. All of this is achieved with the following make commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d12fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! make setup > /dev/null 2>&1\n",
    "! make run > /dev/null 2>&1\n",
    "! make fetch_models > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e392177",
   "metadata": {},
   "source": [
    "We now have the `Llama3.2` model deployed locally.\n",
    "\n",
    "In the lack of internal business documents to use for this demo we will just demonstrate the principles using the Napoleonic Wars Wikipedia page. As a start, in order to test the model's knowledge on the Napoleonic Wars, we will ask the model the following question:\n",
    "\n",
    "> Under the Napoleonic wars, which countries took part in the fifth coalition against France?\n",
    "\n",
    "The core members of the fifth coalition were the Austrian Empire and United Kingdom. As LLMs have randomness built in, we repeat the query five times. From the five answers below, we see that the model either upfront states that it does not know the answer or generates lists that include more or different countries than the actual members of the coalition.\n",
    "\n",
    "A larger model such as OpenAI's GPT-5 would likely have answered correctly but that is besides the point. We are considering the case of internal documents which neither GPT-5 nor our local Llama model knows about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7e484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1:\n",
      "The Fifth Coalition was formed in 1809 and consisted of Austria, Britain, Russia, Sweden, and the Ottoman Empire.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Response 2:\n",
      "I cannot verify which country took part in the Fifth Coalition of the Napoleonic Wars.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Response 3:\n",
      "The fifth coalition against France consisted of Britain and Russia.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Response 4:\n",
      "The Fifth Coalition was formed in 1809, during the Napoleonic Wars. The countries that took part in this coalition were:\n",
      "\n",
      "1. Austria\n",
      "2. Russia\n",
      "3. Sweden-Norway\n",
      "4. Great Britain (United Kingdom)\n",
      "5. Ottoman Empire\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Response 5:\n",
      "The Fifth Coalition was formed against Napoleon's French Empire in 1809. The main countries that participated in this coalition were:\n",
      "\n",
      "1. Austria\n",
      "2. Britain (United Kingdom)\n",
      "3. Russia\n",
      "4. Sweden-Norway\n",
      "5. Prussia\n",
      "\n",
      "These countries came together to oppose Napoleon's expansionist policies and ultimately contributed to the defeat of France at the Battle of Wagram in July 1809.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from backend.rag import query_raw_model\n",
    "\n",
    "q = \"Under the Napoleonic wars, which countries took part in the fifth coalition against France?\"\n",
    "\n",
    "responses = [\n",
    "    query_raw_model(q) for i in range(5)\n",
    "]\n",
    "\n",
    "for i, response in enumerate(responses):\n",
    "    print(f'Response {i+1}:')\n",
    "    print(response)\n",
    "    print(\"-\" * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e3cf7",
   "metadata": {},
   "source": [
    "## Weaviate vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddada90",
   "metadata": {},
   "source": [
    "We will now move on to setting up the vector database containing the internal documents (or in our case the wikipedia page on the Napoleonic Wars).\n",
    "\n",
    "The script `populate_db.py` will fetch Napoleonic Wars Wikipedia page. Each section on the page is split into chunks using an instance of the `RecursiveCharacterTextSplitter` from LangChain. This ensures that chunk divisions follow the section layout of the page which again should ensure higher quality of the chunks. Each chunk is then stored in the Weaviate database including the relevant section title and an embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "970bfe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 155 chunks into the Napoleonic Wars collection\n"
     ]
    }
   ],
   "source": [
    "from scripts import populate_db\n",
    "populate_db.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a563d712",
   "metadata": {},
   "source": [
    "With the chunks added to the database, let's just confirm that the chunks look as expected. For the first chunk we print out the section title, the first 100 characters of the text chunk and the first five elements of the embedding vector. Everything looks fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a834dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section title: Invasion of Russia, 1812\n",
      "Chunk text: The central issue for both Emperor Napoleon I and Tsar Alexander I was control over Poland. Each wan ...\n",
      "Embedding vector: [-0.00635263929143548, 0.03718530014157295, -0.15025673806667328, -0.012791609391570091, 0.0685529112815857] ...\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "collection = client.collections.get('napoleonic_wars')\n",
    "\n",
    "for item in collection.iterator(include_vector=True):\n",
    "    print(f'Section title: {item.properties[\"title\"]}')\n",
    "    print(f'Chunk text: {item.properties[\"text\"][0:100]} ...')\n",
    "    print(f'Embedding vector: {item.vector[\"default\"][0:5]} ...')\n",
    "    break\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd58917",
   "metadata": {},
   "source": [
    "## RAG\n",
    "\n",
    "With the vector database set up, we are now ready to build our RAG Agent. The code for the RAG can be found under [`backend/rag`](https://github.com/crs17/local_rag_demo/blob/main/backend/rag.py). Let's import it and give it a spin! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389a9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend import rag\n",
    "\n",
    "my_RAGAgent = rag.LocalRAGAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44a9941",
   "metadata": {},
   "source": [
    "First let's verify that the vector store is able to find relevant chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "147fd13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 chunks:\n",
      "Section title: War of the Fifth Coalition, 1809\n",
      "The Fifth Coalition (1809) of Britain and Austria against France formed as Britain engaged in the Pe ...\n",
      "Score: 1.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Section title: War of the Fifth Coalition, 1809\n",
      "On land, the Fifth Coalition attempted few extensive military endeavours. One, the Walcheren Expedit ...\n",
      "Score: 0.7424584031105042\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Section title: War of the Fifth Coalition, 1809\n",
      "in French territory, many breaches of the Continental System occurred and the French Continental Sys ...\n",
      "Score: 0.7252911329269409\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Section title: War of the Fifth Coalition, 1809\n",
      "the kingdoms of Denmark–Norway\n",
      "the Kingdom of Spain (under Joseph Bonaparte, Napoleon's elder brothe ...\n",
      "Score: 0.7061325311660767\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "docs = my_RAGAgent.vector_store.similarity_search_with_score(\"Under the Napoleonic wars, which countries took part in the fifth coalition against France?\")\n",
    "print(f'Found {len(docs)} chunks:')\n",
    "for doc, score in docs:\n",
    "    print(f'Section title: {doc.metadata[\"title\"]}')\n",
    "    print(f'{doc.page_content[:100]} ...')\n",
    "    print(f'Score: {score}')\n",
    "    print('-' * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d60e60",
   "metadata": {},
   "source": [
    "This looks good! We can see that the first chunk - which has the highest score - reveals the answer we are looking for.\n",
    "\n",
    "Let's now ask the Agent the same question to see if it does better than the raw model did above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1490da24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Under the Napoleonic wars, which countries took part in the fifth coalition against France?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (7669cd28-30c3-475f-b084-1130d8573b48)\n",
      " Call ID: 7669cd28-30c3-475f-b084-1130d8573b48\n",
      "  Args:\n",
      "    query: Fifth Coalition against France\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'title': 'War of the Fifth Coalition, 1809'}\n",
      "Content: The Fifth Coalition (1809) of Britain and Austria against France formed as Britain engaged in the Peninsular War in Spain and Portugal. The sea became a major theatre of war against Napoleon's allies. Austria, previously an ally of France, took the opportunity to attempt to restore its imperial territories in Germany as held prior to Austerlitz. During the time of the Fifth Coalition, the Royal Navy won a succession of victories in the French colonies. On land the major battles included Battles\n",
      "\n",
      "Source: {'title': 'War of the Fifth Coalition, 1809'}\n",
      "Content: On land, the Fifth Coalition attempted few extensive military endeavours. One, the Walcheren Expedition of 1809, involved a dual effort by the British Army and the Royal Navy to relieve Austrian forces under intense French pressure. It ended in disaster after the Army commander, John Pitt, 2nd Earl of Chatham, failed to capture the objective, the naval base of French-controlled Antwerp. For the most part of the years of the Fifth Coalition, British military operations on land (apart from the\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The countries that took part in the fifth coalition against France were:\n",
      "\n",
      "* Britain\n",
      "* Austria\n",
      "\n",
      "These two countries formed an alliance to counter the French Empire's expansion and influence during the Napoleonic Wars. The war was fought in 1809, with various battles taking place across Europe, including the Walcheren Expedition, which ended in disaster for the British forces.\n"
     ]
    }
   ],
   "source": [
    "query = \"Under the Napoleonic wars, which countries took part in the fifth coalition against France?\"\n",
    "\n",
    "for event in my_RAGAgent.stream(query):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a583b00",
   "metadata": {},
   "source": [
    "In the output above we see first our initial question under \"Human Message\". Under \"Ai Message\" we see that the agent asked the vetor store about information on \"Fifth Coalition against France\" and under \"Tool Message\" we see that the vector store responded with to chunks (the first of which contains the answer we are looking for). Finally, under the last \"Ai Message\" the agent answered the question perfectly. Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def778c7",
   "metadata": {},
   "source": [
    "## Web page chat UI\n",
    "As the last step we will setup the web page chat interface. We can do that by running `make langgraph-run` for the backend and `make ui-setup && make ui-run` for the fronend. In the below screenshot we see that the Agent works with the chat UI and is able to handle follow-up questions:\n",
    "\n",
    "![chat UI interface](static/chat_ui.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fd165",
   "metadata": {},
   "source": [
    "## How to take this to production\n",
    "While this demo works, there are several things to consider before deploying this approach in a production environment:\n",
    "- An ingestion ELT pipeline might be needed depending on the nature of the source documents. For PDF files an extraction mechanism is needed - perhaps OCR.\n",
    "- Again depending on the source documents more advanced chunking mechanism such as semantic chunking could be considered.\n",
    "- Better vector store search could be achieved with a hybrid BM25/embedding approach\n",
    "- Reranking could be deployed for more precise chunk selection\n",
    "- Vector store filtering based on e.g. topics or clients\n",
    "- Monitoring using e.g. Langfuse\n",
    "- Authentication on both UI and backend\n",
    "\n",
    "## TLDR\n",
    "We have here demonstrated how to set up a local RAG agent for making internal documents chattable. We saw how the raw model struggled answering questions on the Napoleonic wars and how adding a RAG agent improved the quality of the answers. While this works, there is still a host of things to consider before deploying this in production.\n",
    "\n",
    "## How I can help\n",
    "Please reach out on [LinkedIn](https://www.linkedin.com/in/chresten-søndergaard/) if I can help with local RAG deployment or other ML/AI endeavors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
